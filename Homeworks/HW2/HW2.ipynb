{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 3000 HW 2\n",
    "\n",
    "## Due: Friday October 3rd @ 11:59 PM EST\n",
    "\n",
    "**Extra Credit Deadline: Wednesday Oct. 1 @ 11:59 PM EST**\n",
    "\n",
    "Earliest Possible Submission: Tuesday Sep. 23\n",
    "\n",
    "Your Name:\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to Gradescope (this can also be done via the assignment on Canvas).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh **`Kernel > Restart & Run All`** just before uploading the `ipynb` file to gradescope.\n",
    "\n",
    "### Tips for success\n",
    "- Start early\n",
    "- Make use of Piazza (also accessible through Canvas)\n",
    "- Make use of Office Hours\n",
    "- Remember to use cells and headings to make the notebook easy to read (if a grader cannot find the answer to a problem, you will receive no points for it)\n",
    "- Under no circumstances may one student view or share their ungraded homework or quiz with another student [(see also)](http://www.northeastern.edu/osccr/academic-integrity), though you are welcome to **talk about** (*not* show each other your answers to) the problems.\n",
    "\n",
    "### Special Note about this HW!\n",
    "\n",
    "- Since you would be working with APIs, i would recommend if you have fully finished Part 1, save your notebook and then work on Part 2 and save your progress! Before you submit you would not have to do **`Kernel > Restart & Run All`**! We do not want you to hit the API call celing. You might have to wait for 24 hours to do the part!\n",
    "\n",
    "### Finally:\n",
    "\n",
    "I designed this homework to provide **less** guidance in each subsequent part; this is on purpose, so that you slowly get used to thinking more critically about how to approach the various tasks. If you are confused as you are working, especially with the later parts, please don't hesitate to reach out for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Sunrise-Sunset API\n",
    "\n",
    "This first part of the homework asks you to complete the pipeline which, given the lattitude / longitude and timezone of some cities:\n",
    "\n",
    "``` python\n",
    "loc_dict = {'Boston': (42.3601, -71.0589, 'US/Eastern'),\n",
    "            'Lusaka': (-15.3875, 28.3228, 'Africa/Lusaka'),\n",
    "            'Sydney': (-33.8688, 151.2093, 'Australia/Sydney')}\n",
    "```\n",
    "\n",
    "the keys are the `name` of the city and the values are tuples of `lat, lon, timezone_name\n",
    "\n",
    "is able to:\n",
    "- query a sunrise / sunset API\n",
    "- clean and process data (timezone management & building `datetime` objects)\n",
    "- For extra credit: produce the a graph of daylight through the year like this:\n",
    "\n",
    "<img src=\"https://i.ibb.co/CBhWtCY/newdaylight.png\" alt=\"newdaylight\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: Getting Sunrise Sunset via API (5 points)\n",
    "Write the `get_sunrise_sunset()` function below so that it uses [this sunrise sunset API](https://sunrise-sunset.org/api) to produce the output (the dictionary) shown in the test case below so that it passes the case.\n",
    "\n",
    "It may be helpful to know that this particular API...\n",
    "- requires no api key\n",
    "- returns about 2.5 queries per second\n",
    "- did not block me when I tried to make 100 consecutive calls as quickly as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have these modules installed\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to write a good docstring! I will do this for you for the other functions in this homework, but you should practice here!\n",
    "def get_sunrise_sunset(lat, lng, date):\n",
    "    \"\"\" WRITE YOUR DOCSTRING HERE\n",
    "    \"\"\"   \n",
    "    \n",
    "    # WRITE YOUR FUNCTIONS HERE AND DELETE THE PASS BELOW\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_dict = get_sunrise_sunset(lat=42.3601, lng=-71.0589, date='2022-02-15')\n",
    "sun_dict_expected = \\\n",
    "{'results': {'sunrise': '11:38:48 AM',\n",
    "            'sunset': '10:17:50 PM',\n",
    "            'solar_noon': '4:58:19 PM',\n",
    "            'day_length': '10:39:02',\n",
    "            'civil_twilight_begin': '11:11:30 AM',\n",
    "            'civil_twilight_end': '10:45:08 PM',\n",
    "            'nautical_twilight_begin': '10:38:37 AM',\n",
    "            'nautical_twilight_end': '11:18:00 PM',\n",
    "            'astronomical_twilight_begin': '10:06:05 AM',\n",
    "            'astronomical_twilight_end': '11:50:33 PM'},\n",
    " 'status': 'OK',\n",
    " 'tzid': 'UTC',\n",
    " 'lat-lng': (42.3601, -71.0589),\n",
    " 'date': '2022-02-15'}\n",
    "\n",
    "assert sun_dict == sun_dict_expected, 'get_sunrise_sunset() error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2 Timezone Considerations: (5 points)\n",
    "\n",
    "It may appear the test case above works, but a look at the API's documentation reminds us: \n",
    "\n",
    "    \"NOTE: All times are in UTC and summer time adjustments are not included in the returned data.\"\n",
    "    \n",
    "Meaning that we would need to change the timezone ourself if comparing different locations. \n",
    "\n",
    "Complete the `change_tz()` below so that it passes the given test case. \n",
    "\n",
    "## Note: If you do not get any response from the `assert` that means everything is correct! If you get a response, then the assert has not passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need these\n",
    "import pytz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have started the function for you\n",
    "def change_tz(dt, timezone_from, timezone_to):\n",
    "    \"\"\" converts timezone of a timezone naive datetime object\n",
    "    \n",
    "    Args:\n",
    "        dt (datetime): datetime (or time) object without timezone\n",
    "        timezone_from (str): timezone of input\n",
    "        timezone_to (str): timezone of output datetime\n",
    "        \n",
    "    Returns:\n",
    "        dt (datetime): datetime object corresponding to \n",
    "            unix_time\n",
    "    \"\"\"\n",
    "    \n",
    "    dt_from = pytz.timezone(timezone_from).localize(dt)\n",
    "    # complete the function and remove the pass below\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build test case input / output\n",
    "dt_no_tz = datetime(2021, 2, 13, 9, 54, 4, 270088)\n",
    "dt_expect = datetime(2021, 2, 13, 14, 54, 4, 270088, tzinfo=pytz.timezone('GMT'))\n",
    "\n",
    "# compute actual output\n",
    "dt = change_tz(dt_no_tz, timezone_from='US/Eastern', timezone_to='GMT')\n",
    "\n",
    "assert dt == dt_expect, 'change_tz() error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build test case input / output\n",
    "dt_no_tz = datetime(2021, 2, 13, 9, 54, 4, 270088)\n",
    "dt_expect = datetime(2021, 2, 13, 9, 54, 4, 270088, tzinfo=pytz.timezone('GMT'))\n",
    "\n",
    "# compute actual output\n",
    "dt = change_tz(dt_no_tz, timezone_from='GMT', timezone_to='GMT')\n",
    "\n",
    "assert dt == dt_expect, 'change_tz() error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3: Turning the dictionary into a Series (5 points)\n",
    "Build `clean_sun_dict()` to pass each of the two test cases below.  Note that:\n",
    "- sunrise and sunset are `time` objects which account for daylight's saving:\n",
    "    - include the date when building these objects\n",
    "    - use `change_tz()` above to cast them to the proper timezone\n",
    "    - build `time` objects by calling `datetime.time()` to discard the date of a `datetime`\n",
    "    - importing `pandas as pd` and using `pd.to_datetime` may also be helpful\n",
    "- `sunrise_hr` and `sunset_hr` are the hours since the day began in local timezone (more easily graphed)\n",
    "    - you may use `.strftime()` and `int()` to cast time objects to strings and then integers (which may be helpful) \n",
    "    \n",
    "**NOTE:** There may be more than one way to accomplish writing this function; as long as the function passes both `assert` test cases, you may continue. Just do be sure to comment and present your code as cleanly as possible. \n",
    "## Important:\n",
    "**NOTE ALSO** that because of the way *I* made the solution, the `sunrise_hr` and `sunset_hr` values are rounded strangely. If you are getting something *close*, you **may** change the test case to match your so that the `assert` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sun_dict(sun_dict, timezone_to):\n",
    "    \"\"\" builds pandas series and cleans output of API\n",
    "    \n",
    "    Args:\n",
    "        sun_dict (dict): dict of json (see ex below)\n",
    "        timezone_to (str): timezone of outputs (API returns\n",
    "            UTC times)\n",
    "            \n",
    "    Returns:\n",
    "        sun_series (pd.Series): all times converted to\n",
    "            time objects\n",
    "    \n",
    "    example sun_series:\n",
    "    \n",
    "    date            2021-02-13 00:00:00\n",
    "    lat-lng        (36.72016, -4.42034)\n",
    "    sunrise                    02:11:06\n",
    "    sunrise_hr                    2.185\n",
    "    sunset                     13:00:34\n",
    "    sunset_hr                   13.0094\n",
    "    dtype: object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Function content here, remove pass below\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_dict = {'results': {'sunrise': '11:38:48 AM',\n",
    "                        'sunset': '10:17:50 PM',\n",
    "                        'solar_noon': '4:58:19 PM',\n",
    "                        'day_length': '10:39:02',\n",
    "                        'civil_twilight_begin': '11:11:30 AM',\n",
    "                        'civil_twilight_end': '10:45:08 PM',\n",
    "                        'nautical_twilight_begin': '10:38:37 AM',\n",
    "                        'nautical_twilight_end': '11:18:00 PM',\n",
    "                        'astronomical_twilight_begin': '10:06:05 AM',\n",
    "                        'astronomical_twilight_end': '11:50:33 PM'},\n",
    "             'status': 'OK',\n",
    "             'lat-lng': (42.3601, -71.0589),\n",
    "             'date': '2022-02-15'}\n",
    "\n",
    "# test without timezone conversion\n",
    "sun_series = clean_sun_dict(sun_dict, timezone_to='GMT')\n",
    "\n",
    "sun_series_exp = pd.Series(\n",
    "{'date': datetime(year=2022, month=2, day=15),\n",
    "'lat-lng': (42.3601, -71.0589),\n",
    "'sunrise': time(hour=11, minute=38, second=48),\n",
    "'sunrise_hr': 11.646666666666667,\n",
    "'sunset': time(hour=22, minute=17, second=50),\n",
    "'sunset_hr': 22.297222222222224})\n",
    "\n",
    "assert sun_series.eq(sun_series_exp).all(), 'clean_sun_dict() error (GMT)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with timezone conversion\n",
    "sun_series = clean_sun_dict(sun_dict, timezone_to='US/Eastern',)\n",
    "\n",
    "sun_series_exp = pd.Series(\n",
    "{'date': datetime(year=2022, month=2, day=15),\n",
    "'lat-lng': (42.3601, -71.0589),\n",
    "'sunrise': time(hour=6, minute=38, second=48),\n",
    "'sunrise_hr': 6.6466666666666665,\n",
    "'sunset': time(hour=17, minute=17, second=50),\n",
    "'sunset_hr': 17.297222222222224})\n",
    "\n",
    "assert sun_series.eq(sun_series_exp).all(), 'clean_sun_dict() error (EST)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.4: Getting our Data Frame (5 points)\n",
    "\n",
    "Write the `get_annual_sun_data()` function so that it produces the outputs shown below.  This function should make use of:\n",
    " - `get_sunrise_sunset()`\n",
    " - `clean_sun_dict()`\n",
    "   \n",
    "as built above. I will start the function for you to help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet:\n",
    "\n",
    "```python\n",
    "loc_dict = {'Boston': (42.3601, -71.0589, 'US/Eastern'),\n",
    "            'Lusaka': (-15.3875, 28.3228, 'Africa/Lusaka'),\n",
    "            'Sydney': (-33.8688, 151.2093, 'Australia/Sydney')}\n",
    "df_annual_sun = get_annual_sun_data(loc_dict, year=2021, period_day=30)\n",
    "df_annual_sun.head(6)\n",
    "```\n",
    "\n",
    "should generate:\n",
    "\n",
    "|    |   city |       date |              lat-lng |  sunrise | sunrise_hr |   sunset | sunset_hr |\n",
    "|---:|-------:|-----------:|---------------------:|---------:|-----------:|---------:|----------:|\n",
    "|  0 | Boston | 2021-01-01 |  (42.3601, -71.0589) | 07:11:49 |   7.196944 | 16:24:12 | 16.403333 |\n",
    "|  1 | Lusaka | 2021-01-01 |  (-15.3875, 28.3228) | 05:38:33 |   5.642500 | 18:42:09 | 18.702500 |\n",
    "|  2 | Sydney | 2021-01-01 | (-33.8688, 151.2093) | 05:46:24 |   5.773333 | 20:10:53 | 20.181389 |\n",
    "|  3 | Boston | 2021-01-31 |  (42.3601, -71.0589) | 06:56:43 |   6.945278 | 16:58:42 | 16.978333 |\n",
    "|  4 | Lusaka | 2021-01-31 |  (-15.3875, 28.3228) | 05:55:43 |   5.928611 | 18:44:35 | 18.743056 |\n",
    "|  5 | Sydney | 2021-01-31 | (-33.8688, 151.2093) | 06:14:24 |   6.240000 | 20:02:42 | 20.045000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be useful\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annual_sun_data(loc_dict, year=2021, period_day=30): \n",
    "    \"\"\" pulls evenly spaced sunrise / sunsets from API over year per city\n",
    "    \n",
    "    Args:\n",
    "        loc_dict (dict): keys are cities, values are tuples of \n",
    "            (lat, lon, tz_str) where tz_str is a timezone\n",
    "            string included in pytz.all_timezones\n",
    "        year (int): year to query\n",
    "        period_day (int): how many days between data queries\n",
    "            (i.e. period_day=1 will get every day for the year)\n",
    "            \n",
    "    Returns:\n",
    "        df_annual_sun (DataFrame): each row represents a \n",
    "            sunrise / sunset datapoint, see get_sunrise_sunset()\n",
    "    \"\"\"\n",
    "\n",
    "    cycle_day = pd.to_datetime(f'{year}-01-01')\n",
    "    cycle_city = loc_dict.keys()\n",
    "    df_annual_sun = pd.DataFrame()\n",
    "    \n",
    "    while cycle_day.year == year:\n",
    "        for city in cycle_city:\n",
    "            city_series = pd.Series({'city': city})\n",
    "\n",
    "            #continue the for loop, using the two functions you've already written\n",
    "\n",
    "        #continue the while loop until you reach the end of the year\n",
    "    \n",
    "    # remove the pass below and include a return statement\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_dict = {'Boston': (42.3601, -71.0589, 'US/Eastern'),\n",
    "            'Lusaka': (-15.3875, 28.3228, 'Africa/Lusaka'),\n",
    "            'Sydney': (-33.8688, 151.2093, 'Australia/Sydney')}\n",
    "\n",
    "# you may find that setting period_day to a larger value is quicker for debug\n",
    "# period_day=5 takes about a minute or so given the API does 2-3 requests / sec\n",
    "df_annual_sun = get_annual_sun_data(loc_dict, year=2021, period_day=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annual_sun.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.5: Plotting the data (5 points)\n",
    "\n",
    "Using [plt.fillbetween()](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.fill_between.html), like [this example](https://colab.research.google.com/drive/1eYuuwGwQKEa6x84fqpdVlf46sXLDmhCZ?usp=sharing), write the `plot_daylight()` function so that:\n",
    "\n",
    "``` python\n",
    "plot_daylight(df_annual_sun)\n",
    "```\n",
    "\n",
    "produces a similar graph to:\n",
    "\n",
    "<img src=\"https://i.ibb.co/CBhWtCY/newdaylight.png\" alt=\"newdaylight\" style=\"width: 500px;\"/>\n",
    "\n",
    "Be sure that your graph displays in Jupyter notebook (no need to save it in another form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules you might use\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "\n",
    "def plot_daylight(df_annual_sun):\n",
    "    \"\"\" produces a plot of daylight seen across cities\n",
    "    \n",
    "    Args:\n",
    "        df_annual_sun (DataFrame): each row represents a \n",
    "            sunrise / sunset datapoint, see get_sunrise_sunset()\n",
    "    \"\"\"\n",
    "    \n",
    "    # Function content here, remove pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about a minute to run with period_day=7, worth the wait to characterize\n",
    "# the sudden jumps due to daylight savings times\n",
    "df_annual_sun = get_annual_sun_data(loc_dict, year=2021, period_day=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daylight(df_annual_sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: NASA API\n",
    "\n",
    "![NASA](https://www.nasa.gov/wp-content/uploads/2025/06/54614323748-5967d5c0c5-o.jpg)\n",
    "\n",
    "In this part, you would be using the NASA Power API (https://power.larc.nasa.gov/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with OpenWeather, we need to obtain the API key from [here](https://api.nasa.gov/). This is much simpler than other APIs. The API key will be emailed to you. Make sure you use that api key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1: Obtaining data from the NASA Power API (5 points)\n",
    "\n",
    "In this task, you need to collect 1 month of daily environmental data from the NASA POWER API for your **Favorite Place**. For example Prof. Singhal's favorite place is Tokyo. You need to find the latitudes and longitudes of your favorite place and obtain the data. \n",
    "\n",
    "Additionally, you need to provide the API with the start and end dates. For the end date, you need to use `datetime.now().strftime('%Y%m%d')` and the start date would be 30 days before this date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_nasa_data(start_date, end_date, api_key='[YOUR API KEY HERE]'):\n",
    "    \"\"\"Takes the start and end date and fetches the Power data.\n",
    "    \n",
    "    Args:\n",
    "        start_date (str): the start date of data collection\n",
    "        end_date (str): the end date of data collection\n",
    "        api_key (str): API key of the student\n",
    "\n",
    "    Returns:\n",
    "        json of the power data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fill this with your own (Make sure you change the Lat and Long) \n",
    "    \n",
    "    lat = 36.39\n",
    "    \n",
    "    long = 25.46\n",
    "    \n",
    "    base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "    \n",
    "    params = {\n",
    "    \"start\": start_date,\n",
    "    \"end\": end_date,\n",
    "    \"latitude\": lat,\n",
    "    \"longitude\": long,\n",
    "    \"community\": \"RE\",\n",
    "    \"parameters\": \"T2M_MAX,PRECTOTCORR,ALLSKY_SFC_SW_DWN\",\n",
    "    \"format\": \"JSON\",\n",
    "    \"api_key\": api_key\n",
    "    } \n",
    "\n",
    "\n",
    "    # return the output\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here compute the start and end date:\n",
    "\n",
    "end_date=\n",
    "start_date =\n",
    "\n",
    "raw_data = get_nasa_data(start_date, end_date)\n",
    "\n",
    "#uncomment to see if the code works\n",
    "# print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2: Build a dictionary from the output (5 points)\n",
    "\n",
    "In this part, you need to create a dictionary where each key is a date, and the value is another dictionary with variables like temperature, solar radiation, and preciptation. These are the three things you already passed as parameters in the last part. \n",
    "\n",
    "Save the daily values of `T2M_MAX` as the key name: `max_temp_C`, `PRECTOTCORR` as `precip_mm`, and `ALLSKY_SFC_SW_DWN` as `solar_rad_kWh`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3: Convert the dictionary to a pandas dataframe (5 points)\n",
    "\n",
    "Now convert the dictionary that you created in Part 2.2 into a pandas dataframe and print the first 20 rows.\n",
    "\n",
    "Make sure that each row name is the date and the dates are in the following format '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.4: Cleaning/manipulating (5 points)\n",
    "\n",
    "Convert the values of temperature from Celsius to Fahrenheit. Additionally, normalize the values that are in `solar_rad_kWh` and save the values of the normalized values as a new column and chnage the index coloumn as date.\n",
    "\n",
    "Print the final dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.5: Plotting (5 points)\n",
    "\n",
    "Using plotly, make the following plots as line plots:\n",
    "- of date (x-axis) versus max_temp_F (y-axis) that has the solar_rad_kWh as hover data.\n",
    "- of date (x-axis) versus precip_mm (y-axis) that has the solar_rad_kWh as hover data.\n",
    "- of date (x-axis) versus solar_rad_norm (y-axis) that has the solar_rad_kWh as hover data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Web Scraping EuroMillions Results Continued...\n",
    "\n",
    "For this problem, we continue with creating a small data set scraped from [Euro-Millions](https://www.euro-millions.com/) which is a lottery that is played across nine European countries. Draws take place on Tuesday and Friday evenings with a minimum guaranteed jackpot of €17 million. **The beginning of this problem was on Lab 1; you will need to use the functions you built for Part 2 to complete this assignment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the below with the corresponding function from Lab 1, Part 2.1\n",
    "\n",
    "def get_lottery_html(code):\n",
    "    \n",
    "    pass\n",
    "\n",
    "url_text = get_lottery_html('13-09-2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the below with the corresponding function from Lab 1, Part 2.2\n",
    "\n",
    "def get_country_soup(html, country):\n",
    "    \n",
    "    pass\n",
    "\n",
    "country_choice = 'BE'\n",
    "my_country_soup = get_country_soup(url_text, country_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.1: Cleaning a Country (10 points)\n",
    "\n",
    "Below is the function `clean_country_df()`, which takes the soup object from the previous function and creates a data frame with the following columns:\n",
    "\n",
    "    - `balls`: the number of balls matched\n",
    "    - `stars`: the number of stars matched\n",
    "    - `ppw`: the prize per winner\n",
    "    - `country_winners`: how many winners of the prize in the given country\n",
    "    - `total_winners`: the total number of winners\n",
    "    - `country`: the country name\n",
    "    - `currency`: the currency of the lottery\n",
    "\n",
    "I have written the function and (*given your function from lab works*) it should work. **DO NOT CHANGE ANYTHING IN THE BODY OF THE FUNCTION.**\n",
    "\n",
    "**In a markdown cell** create a bullet point list where you explain each what each chunk of code does. Your bullet point list should have **THREE** sections, with **NINE** total bullet points/explanations corresponding to the chunks below the `# EXPLAIN THIS (number)` comments. You must accurately summarize the content of each code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "import re\n",
    "\n",
    "def clean_country_df(soup, country_name = \"BE\"):\n",
    "    \"\"\"Takes the soup of a country and cleans it, creating a data frame.\n",
    "    \n",
    "    Args:\n",
    "        soup (soup): the soup from get_country_soup\n",
    "        country_name (str): name of the country (make sure this matches with the code used in the previous part)\n",
    "\n",
    "    Returns:\n",
    "        clean_country_df (DataFrame): a DataFrame with seven columns corresponding to\n",
    "            balls matched\n",
    "            stars matched\n",
    "            prize per winner\n",
    "            country winners\n",
    "            total winners\n",
    "            country\n",
    "            currency\n",
    "    \"\"\"\n",
    "    # EXPLAIN THIS (1.1)\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # EXPLAIN THIS (1.2)\n",
    "    headers = [th.get_text(strip=True) for th in table.find('thead').find_all('th')]\n",
    "\n",
    "    # EXPLAIN THIS (1.3)\n",
    "    country_winner_index = next((i for i, header in enumerate(headers) if 'Winners' in header and 'Total' not in header), None)\n",
    "\n",
    "    # EXPLAIN THIS (1.4)\n",
    "    balls_matched = []\n",
    "    stars_matched = []\n",
    "    prize_per_winner = []\n",
    "    country_winners = []\n",
    "    total_winners = []\n",
    "    currencies = []\n",
    "    \n",
    "    # Process each row in the table body, excluding the last totals row\n",
    "    for row in table.find('tbody').find_all('tr')[:-1]:\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        # EXPLAIN THIS (2.1)\n",
    "        numbers_matched = columns[0].get_text(strip=True)\n",
    "        prize = columns[1].get_text(strip=True)\n",
    "        country_winner = columns[country_winner_index].get_text(strip=True) if country_winner_index is not None else 'N/A'\n",
    "        total_winner = columns[-1].get_text(strip=True)\n",
    "        \n",
    "        # EXPLAIN THIS (2.2)\n",
    "        currency_match = re.match(r'^\\D*', prize)\n",
    "        currency = currency_match.group(0) if currency_match else 'N/A'\n",
    "        currencies.append(currency)\n",
    "        \n",
    "        # EXPLAIN THIS (2.3)\n",
    "        numeric_prize = pd.to_numeric(prize.replace(currency, '').replace(',', ''), errors='coerce')\n",
    "        \n",
    "        # EXPLAIN THIS (2.4)\n",
    "        numbers_split = numbers_matched.split('+')\n",
    "        balls = pd.to_numeric(numbers_split[0].strip().replace(',', ''), errors='coerce')\n",
    "        stars = pd.to_numeric(numbers_split[1].strip().replace(',', ''), errors='coerce') if len(numbers_split) > 1 else 0\n",
    "\n",
    "        balls_matched.append(balls)\n",
    "        stars_matched.append(stars)\n",
    "        prize_per_winner.append(numeric_prize)\n",
    "        country_winners.append(pd.to_numeric(country_winner.replace(',', ''), errors='coerce'))\n",
    "        total_winners.append(pd.to_numeric(total_winner.replace(',', ''), errors='coerce'))\n",
    "    \n",
    "    # EXPLAIN THIS (3)\n",
    "    data = {\n",
    "        'balls': balls_matched,\n",
    "        'stars': stars_matched,\n",
    "        'ppw': prize_per_winner,\n",
    "        'country_winners': country_winners,\n",
    "        'total_winners': total_winners,\n",
    "        'country': [country_name] * len(balls_matched),\n",
    "        'currency': currencies\n",
    "    }\n",
    "    \n",
    "    clean_country_df = pd.DataFrame(data)\n",
    "    \n",
    "    return clean_country_df\n",
    "\n",
    "# Example usage\n",
    "clean_df = clean_country_df(my_country_soup, 'BE')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer in this cell:\n",
    "- Explain Code Chunks 1:\n",
    "  \n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "- Explain Code Chunks 2:\n",
    "  \n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "- Explain Code Chunk 3:\n",
    "\n",
    "    -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.2: Stacking the Countries (5 points)\n",
    "\n",
    "Complete the function `stack_countries_df()` below (including docstring) which takes as an argument a list of country codes (strings) and a list of dates (strings), and uses the functions from the previous three parts to create a single data frame with results across those countries and dates. There may be multiple ways to do this, but one way could be to first loop through the dates, use the `get_lottery_html()` function, then loop through the countries and apply the other two functions. You will also want to add a column with the date information to the final data frame.\n",
    "\n",
    "**Make sure to remove the `pass` statement when you are finished.** Then, also make sure to run the code to ensure your function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_countries_df(country_list, date_list):\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = ['BE', 'GB', 'CH']\n",
    "dates = ['26-04-2024', '30-04-2024']\n",
    "combined_df = stack_countries_df(country_codes, dates)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.3: EDA and Data Viz (10 points)\n",
    "\n",
    "The first code cell below runs your function from part 4 to get the lottery results for Belgium and France over the month of April 2024. Use this data frame to:\n",
    "\n",
    "- Create a subset which contains only the 5 ball, 0 star winners\n",
    "- Plot a line plot that compares the number of 5 ball, 0 star winners for in Belgium and France over April\n",
    "\n",
    "**Then, in a markdown cell** discuss briefly what this plot tells you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = ['BE', 'FR']\n",
    "dates = ['02-04-2024', '05-04-2024', '09-04-2024', \n",
    "         '12-04-2024', '16-04-2024', '19-04-2024', \n",
    "         '23-04-2024', '26-04-2024', '30-04-2024']\n",
    "combined_df = stack_countries_df(country_codes, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the subset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the line plot here (you may use matplotlib or plotly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Summarizing and Visualizing Data\n",
    "\n",
    "For this part, you will use the `players_fifa23.csv` from Canvas to investigate the ratings for soccer players in the FIFA 23 video game. Make sure the `.csv` is in the same directory as this notebook file.\n",
    "\n",
    "**Note**: You do not need to know anything about soccer or video games to complete this problem, only perhaps that a higher `Overall` rating is considered a good thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.1: Plotting Data (15 points)\n",
    "\n",
    "Create a plotly scatter plot which shows the mean `Overall` rating for soccer players (rows) of a given `Nationality` for a particular `Age`. Focuse on three countries (`England`, `Germany`, `Spain`). In other words, your plot's x-axis should be `Age`, the y-axis should be `Overall`, and there should be three different colored points at each `Age`, one for each `Nationality`.\n",
    "\n",
    "Export your graph as an html file `age_ratings_nationality.html`. You do not have to submit it with this homework, but the code should show that you did this.\n",
    "\n",
    "Hints:\n",
    "- There may be multiple ways/approaches to accomplish this task.\n",
    "- One approach: you may use `groupby()` and boolean indexing to build these values in a loop which runs per each `Nationality`.\n",
    "- `px.scatter()` will only graph data from columns (not the index).  Some approaches may need to graph data from the index.  You can use [df.reset_index()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html) to make your index a new column as shown [in this example](https://colab.research.google.com/drive/1d9JDphmpSTg9NtFMyfFnMQ6RmIx6zChK?usp=sharing)\n",
    "- In some approaches you may need to pass multiple rows to [df.append()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html) if need be as shown [in this example](https://colab.research.google.com/drive/1XbBHMcYq_2Q225nkKs3j06iigCQGmM4H?usp=sharing)\n",
    "- In some approaches you may need to go from \"wide\" data to \"long\" data by using [df.melt()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.melt.html) as discussed [here](https://towardsdatascience.com/reshaping-a-pandas-dataframe-long-to-wide-and-vice-versa-517c7f0995ad)\n",
    "- The first few code cells below get you started with looking at the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to read in the data\n",
    "import pandas as pd\n",
    "\n",
    "df_fifa = pd.read_csv('players_fifa23.csv', index_col = 'ID')\n",
    "df_fifa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fifa.Nationality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fifa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fifa['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the plot\n",
    "import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.2: Numerical Summaries (10 points)\n",
    "\n",
    "1. Calculate the sample mean and median of `Overall` for the entire data set. In a markdown cell, discuss what their relative values imply about the distribution of `Overall`, and then use the plot from 1.1 and these values to discuss whether you think English, German, and Spanish players are generally better rated than other country's players, and at what age do they become average players?\n",
    "2. Calculate the `.group_by()` function to calculate the means and standard deviations of `Overall` for the three Nationalities in Part 1.1 (you will want to use the original data frame or a slightly modified version of it (the `.isin` function from pandas may help), **NOT** the data frame you used for the plot). What do these values tell you about the differences between English, German, and Spanish players?\n",
    "3. Create a subset of the original data frame that includes only `Age`, `Height`, `Weight`, and `Overall`. Calculate the correlation matrix for these four features and discuss what the relationships seem to be and whether those relationships make sense to you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
